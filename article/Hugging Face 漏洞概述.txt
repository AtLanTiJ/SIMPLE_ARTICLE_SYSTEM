Hugging Face是一个提供机器学习模型托管和共享的平台，但近年来也出现了一些安全漏洞和问题。以下是一些主要的漏洞和安全事件：

实习生破坏模型训练事件：据报道，一名实习生因不满资源分配，利用Hugging Face的漏洞在共享模型中注入破坏代码，导致模型训练效果不稳定，无法达到预期效果。该实习生已被辞退，并且字节跳动已将此事同步给相关联盟和学校
。

反序列化漏洞：Hugging Face的transformers库中的load_repo_checkpoint()函数存在漏洞，允许通过反序列化不可信数据执行任意代码，这可能导致远程代码执行（RCE）
。

架构漏洞：云安全公司Wiz发现Hugging Face平台上的两个关键架构漏洞，这些漏洞可能允许攻击者上传恶意AI模型并篡改容器注册表，从而获取对其他客户数据的未授权访问
。

恶意模型上传：腾讯朱雀实验室发现Hugging Face的开源组件datasets存在不安全特性，可能导致供应链后门投毒攻击，使得AI开发者在使用该组件加载恶意数据集时，其PC/服务器可能被入侵
。

未授权访问：Hugging Face的安全团队检测到其Spaces平台的未授权访问，这可能涉及到访问认证密钥的泄露。作为预防措施，Hugging Face撤销了一些令牌，并建议用户刷新访问密钥或切换到更安全的令牌
。

恶意模型扫描：JFrog安全研究团队发现Hugging Face平台上大约有100个机器学习模型被上传，这些模型可能允许攻击者在用户机器上注入恶意代码。这些模型在加载时会执行代码，为攻击者提供了一个持久的后门，构成了数据泄露和间谍攻击的重大风险
。

CI/CD接管风险：Wiz研究人员发现，Hugging Face上的一些AI模型共享了推理基础设施，这可能导致攻击者接管CI/CD管道并执行供应链攻击
。

这些问题表明，即使是大型的AI平台也可能面临安全挑战。Hugging Face已经采取了一些措施来提高安全性，例如与Wiz合作使用漏洞扫描和云环境配置工具，以及开发了一种新的安全格式safetensors来存储模型数据。然而，这些事件提醒我们，在使用开源模型和数据集时，需要保持警惕并采取适当的安全措施。


Hugging Face漏洞的产生主要有以下几个原因：

恶意模型上传：Hugging Face平台上存在恶意模型，这些模型在加载时会执行代码，给攻击者提供了在受感染机器上获得完整控制的能力，实现基于开源模型的后门植入。这些恶意模型的潜在威胁包括直接的代码执行，可能导致数据泄露、系统损坏或其他恶意行为。据JFrog安全团队监控发现，Hugging Face平台上至少有100多个恶意的AI ML模型实例，例如baller423/goober2模型在受害者的机器上直接执行代码，并为攻击者提供持久化的后门访问权限
。

API令牌漏洞：安全公司Lasso Security发现Hugging Face上存在API令牌漏洞，黑客可以获取微软、谷歌、Meta等公司的令牌，并能够访问模型库，污染训练数据或窃取、修改AI模型。由于平台的令牌信息写死在API中，黑客可以直接从Hugging Face及GitHub的存储库获得平台上各模型分发者的API令牌
。

数据集组件的安全风险：腾讯朱雀实验室发现Hugging Face开源组件datasets存在不安全特性，这可能会导致供应链后门投毒攻击风险。当开发者使用该组件加载包含恶意代码的数据集时，可能会导致PC/服务器被入侵，同时在大模型预训练、微调等场景中，还可能导致大模型参数被窃取或篡改
。

反序列化漏洞：Hugging Face Transformers库在加载PyTorch模型时，使用的torch.load()函数会执行反序列化操作，恶意代码正是在这个过程中完成加载执行。攻击者通过在模型文件中植入恶意的序列化数据实现攻击
。

未授权访问：Hugging Face团队检测到对其Spaces平台的未经授权访问，可能导致部分用户密钥泄露。这可能是由于网络攻击数量的增加，部分原因是使用量的大幅增长
。

为了缓解这些漏洞，Hugging Face已经采取了一些措施，包括开发了一种新的格式Safetensors来安全地存储模型数据，其中只对模型关键数据进行存储，不包含可执行代码。此外，Hugging Face平台已经实施了几项安全措施，如恶意软件扫描、Pickle扫描和Secret扫描，以检测仓库中的恶意代码、不安全的反序列化以及敏感信息
。

